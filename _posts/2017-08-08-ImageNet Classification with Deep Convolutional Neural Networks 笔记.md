---
title: ImageNet Classification with Deep Convolutional Neural Networks 笔记
date: 2017-08-08 16:35:52
math: y
---
#### 论文介绍
本文训练了一个深度卷积神经网络（下文称CNNs）来将ILSVRC-2010中1.2M（注：本文中M和K均代表 百万/千 个数量）的高分辨率图像（注：ImageNet目前共包含大约22000类，15兆左右的标定图像，ILSVRC-2010为其中一个常用的数据集）数据分为1000类。测试结果，Top-1和Top-5的错误率分别为37.5%和17%，优于当时最优的水平。

后来作者利用该种模型的变体参与了ILSVRC-2012（ImageNet Large Scale Visual Recognition Challenge）比赛，以Top-5错误率15.3%遥遥领先亚军的26.2%。最后文章发表于NIPS 2012（Neural Information Processing Systems），目的是Hinton与其学生为了回应别人对于deep learning的质疑而将deep learning用于ImageNet（图像识别目前最大的数据库）上。

#### 网络结构
![网络结构](http://i2.bvimg.com/595056/325f0bff626762e1.jpg)

该神经网络包含60M参数和650K神经元，用5个卷积层（其中某些层与亚采样层连接）、三个全连接层（包括一个1K门的输出层）。为使训练更快，文章采用非饱和神经元，并利用了一个高效的GPU应用进行卷积运算。在全连接层中，为避免过拟合，文章采用了一种叫做“dropout”的方法。

由上图可以总结Alex-net:Input(224,224,3)→96F1(11,11,3,s=4)→LRN→max-P1(3,3,2)→256F2(3,3,96)→LRN→max-P2(3,3,2)→384F3(3,3,192)→384F4(3,3,192)→256F5(3,3,192)→max-P3(3,3,2)→4096fc1→4096fc2→Classifer1000

#### 突出贡献
- 基于ILSVRC-2010和ILSVRC-2012的子集训练了一个最大的CNNs模型并达到了该数据集中的当前最优结果。
- 写了一个在GPU中高度优化的二维卷积的实现以及其他一些固有的CNNs的训练操作（代码：http://code.google.com/p/cuda-convnet/）。
- 网络中包括了大量不常见和新的特征来提升性能，减少训练时间。
- 文章网络的大小导致过拟合成为一个严重的问题，所以文章采取了一些有效的技术来预防过拟合。（详见：四 降低过拟合）
- 把Hinton 10年提出的用于改善RBM性能的ReLu引入CNN中，使得ReLu成为以后深度网络普遍使用的非线性函数，从而替代了经典的sigmoid，tanh函数。

最终网络大小主要受限于GPU的内存和训练时间。实验证明，本网络在有两个GTX 580 3GB GPU的机器上训练了5-6天。实验结果显示，如果GPU更快或数据集更大，实验结果将会更好。

#### 学而时习
- ReLu非线性不饱和函数（相对于tanh或sigmoid函数，在x非常大或非常小时，函数输出基本不变，故称为饱和函数），又称为扭曲线性函数，不但保留了非线性的表达能力，而且还具有线性性质（正值部分），相比tanh和sigmoid函数在误差反向传递时，不会有由于非线性引起的梯度弥散现象（顶层误差较大，由于逐层递减误差传递，引起底层误差很小，导致深度网络底层权值更新量很小，从而导致深度网络局部最优）。
- 数据增强---图像平移，水平翻转。操作过程是：给定一个原始图像a 1080 * 780，要得到224 * 224的训练样本，可以先把a缩小到b 360 * 256，然后在b的中心取256 * 256的图片得到c，然后再在c上随机提取224 * 224的图片作为训练样本，最后再结合图像水平翻转来增加样本从而达到数据增益。
- 数据增强---调整RGB通道强度。个人理解也就是对图片进行主成份分析，然后给RGB分别加上一个量，这样可以成倍增加已有主成分，这种技术利用了捕捉自然图像的一个重要性质，即改变颜色和像素值，物体是不变的。
- 使用重叠pooling（filter size > strides），不容易过拟合。
- 测试方法---在待测图片的四角和中心提取5个片段，在水平翻转后形成10个样本，输入网络结果求平均。

#### 困惑吧啦吧啦
- Alex-net网络中layer-3的filter把layer-2的所有特征图作为输入，而其它卷积层，只从同一个GPU内的上一层特征图作为输入。为什么layer-3把layer-2的全部特征图作为输入而且它层却不这样，并没有给出解释理论依据，只是说通过交叉验证实验得来。
- 无论在什么初始值下，两个GPU也就是两个相同的结构，学习到的卷积核不一样，GPU1学习到的特征大多数颜色不明确，GPU2学习到的特征大部分具备颜色。
- 局部加权回归-待续

***
#### more information
[ImageNet Classification with Deep Convolutional Neural Networks](http://pan.baidu.com/s/1miifbXe)